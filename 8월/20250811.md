### :link: 2025-08-11
- [gunicorn + llm](#gunicorn--llm)
 
&nbsp;
### gunicorn + llm
**Uvicon과 Gunicorn의 차이점**
- Uvicon: 개발 환경, in-memory 환경
- Gunicorn: unicorn 및 worker 관리, 운영/배포 대상, 안정성 위주.
#### 1) main.py

```python
import uvicorn
from dotenv import load_dotenv
import uuid
from typing import List, Annotated

from fastapi import FastAPI, Form, HTTPException, Request

from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
from langchain_core.messages import BaseMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.runnables.history import RunnableWithMessageHistory
from pydantic import BaseModel, Field

load_dotenv()

model = ChatOpenAI(
    model="gpt-4.1-mini",
    temperature=0.7
)

prompt = ChatPromptTemplate.from_messages([
    ('system', '넌 IT 분야 최고의 직업 상담사야. 진로를 고민하는 취업준비생들에게 현실적이지만 용기를 줄 수 있는 말투로 상담해줘. 단 모든 응답은 **한국어**로 답변해야 해'),
    MessagesPlaceholder(variable_name='history'),
    ('human', '{query}')
])

chain = prompt | model

store = {}

def get_by_session_id(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

chain_with_history = RunnableWithMessageHistory(
    runnable=chain,
    get_session_history=get_by_session_id,
    input_messages_key='query',
    history_messages_key='history'
)

app = FastAPI(title='IT 진로 상담 챗봇 API')

@app.post('/chatbot', summary='챗봇에게 메시지 전송') 
async def chatbot(query: Annotated[str, Form(...)], session_id: Annotated[str, Form(...)]):
    if session_id not in store:
        raise HTTPException(status_code=404, detail='session_id not found')
    response = chain_with_history.invoke(
        {'query': query},
        config={'configurable': {'session_id': session_id}} 
    )
    return response.content

@app.post('/init_conversation')
async def init_conversation():
    session_id = str(uuid.uuid4())
    get_by_session_id(session_id)
    return {'session_id': session_id}

@app.delete('/remove_conversation')
async def remove_conversation(session_id: Annotated[str, Form(...)]):
    if session_id in store:
        store.pop(session_id)
    else:
        raise HTTPException(status_code=404, detail='session _id not found')

if __name__ == '__main__':
    uvicorn.run(app, host='0.0.0.0', port=8000)
```

#### 2) Dockerfile

```dockerfile
FROM python:3.12 AS python-base

WORKDIR /app

COPY . /app

RUN pip install --upgrade pip
RUN pip install -r requirements.txt

# gunicorn 서버의 포트와 맞춰줌
EXPOSE 8000

CMD [ "gunicorn", "-c", "gunicorn.config.py" ]

# docker run -d -p 8000:8000 --env-file .env sortofel/chatbot:gunicorn
# --env-file; env 실행시만 주입
```

#### 3) gunicorn.config.py

```python
import multiprocessing

# CPU 코어 수에 기반하여 워커 수 설정 (일반적으로 (코어 수 * 2) + 1)
workers = multiprocessing.cpu_count() * 2 + 1 

# Gunicorn에서 사용할 워커 클래스 (비동기 ASGI 서버로 Uvicorn 사용)
worker_class = 'uvicorn.workers.UvicornWorker'

# 실행할 WSGI 어플리케이션 (main.py의 app 객체)
wsgi_app = 'main:app'

# 서버 바인딩 주소 및 포트 (모든 네트워크 인터페이스에서 8000 포트로 수신)
bind = '0.0.0.0:8000'

# 로깅 레벨 설정: debug, info(기본값), warning, error, critical
loglevel = 'info'

# 각 워커가 처리할 최대 요청 수
max_request = 500
```