### :link: 2025-08-08
- [FastAPI](#fastapi)
 
&nbsp;
### FastAPI
FastAPI, LangChain 및 RAG 활용 실습 내용

#### 1) 기본 API 서버 (`GET /`)

* "Hello, AI Agent!" 메시지 반환

```python
@app.get("/")
async def get_root():
    return {
        "message": "Hello, AI Agent!"
    }
```

#### 2) LLM 연동 API (`POST /chat`)

* 기능: 사용자 질문을 받아 OpenAI LLM(ChatOpenAI)을 호출하고 답변을 반환.
* 요청 데이터 형식:

```json
{
  "query": "질문"
}
```

```python
@app.post("/chat")
def chat_with_llm(user_query: UserQuery):
    model = ChatOpenAI(
        model='gpt-4.1-mini',
        temperature=1
    )
    return model.invoke(user_query.query)
```

#### 3) RAG 기반 질의응답 API (`POST /rag-qa`)

* `my_document.txt`를 기반으로 질문에 답변.

```python
@app.post("/rag-qa")
def rag_qa(user_query: UserQuery):
    loader = TextLoader('./my_document.txt')
    document = loader.load()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=100,
        chunk_overlap=5
    )
    docs = splitter.split_documents(document)

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vector_store = FAISS.from_documents(docs, embeddings)

    template = """당신은 주어진 문맥(context)만을 사용하여 질문에 답변하는 유쾌한 AI 어시스턴트 입니다.
    문맥에서 답을 찾을 수 없다면, '주어진 정보만으로는 답변할 수 없습니다.'라고 말하세요. 절대 내용을 꾸며내지 마세요.

    Context: {context}

    Question: {question}

    Answer:
    """
    prompt = PromptTemplate(
        template=template,
        input_variables=['context', 'question']
    )

    model = ChatOpenAI(
        model='gpt-4.1-mini',
        temperature=1
    )
    parser = StrOutputParser()

    def get_retrieval(query: str):
        retrieved_docs = vector_store.similarity_search(query)
        formatted_context = "\n".join(d.page_content for d in retrieved_docs)
        return formatted_context

    chain = RunnablePassthrough() | prompt | model | parser

    return chain.invoke({
        "context": get_retrieval(user_query.query),
        "question": user_query.query
    })
```

#### 4) 실행 및 테스트

**서버 실행**

```bash
uvicorn main:app --reload
```

**기본 API 테스트**

```zsh
GET http://127.0.0.1:8000/

{
  "message": "Hello, AI Agent!"
}
```

**LLM API 테스트**

```zsh
POST http://127.0.0.1:8000/chat
Content-Type: application/json

{
  "query": "오늘 서울에 비가 올까요?"
}

# "현재 실시간 날씨 정보를 제공할 수는 없으나, 서울의 오늘 날씨와 비 예보를 확인하려면 기상청 웹사이트나 날씨 앱을 참고하는 것을 추천드립니다. 필요하시다면 최신 서울 날씨 예보를 확인할 수 있는 사이트 링크를 안내해 드릴 수도 있습니다."
```

**RAG API 테스트**

```zsh
POST http://127.0.0.1:8000/rag-qa
Content-Type: application/json

{
  "query": "앨리스가 다과회를 떠나기로 결심한 이유는?"
}

# "앨리스는 이토록 무례하고 의미 없는 다과회는 난생 처음이라며 분노를 참지 못하고 자리를 박차고 일어났기 때문에 다과회에서 떠났습니다."
```