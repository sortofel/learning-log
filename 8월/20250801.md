### :link: 2025-08-01
- [FFMPEG ì„¤ì¹˜ ì˜¤ë¥˜ì™€ MacPort ì„¤ì¹˜](#0-ffmpeg-ì„¤ì¹˜-ì˜¤ë¥˜ì™€-macport-ì„¤ì¹˜)
- [Voice Chat](#1-voice-chat)
 
&nbsp;
### 0. FFMPEG ì„¤ì¹˜ ì˜¤ë¥˜ì™€ MacPort ì„¤ì¹˜
ì´ ì‹¤ìŠµì€ FFMPEG ë¼ ë¶ˆë¦¬ëŠ” ë¯¸ë””ì–´ íŒŒì¼ ë³€í™˜ í”„ë¡œê·¸ë¨ì„ ì„¤ì¹˜í–ˆì–´ì•¼ í–ˆë‹¤.
ë‚˜ëŠ” ë§¥ì„ ì‚¬ìš©í•˜ê³  ìˆì–´ì„œ, homebrewë¡œ ì„¤ì¹˜ë¥¼ ì‹œë„í–ˆì—ˆë‹¤.
```zsh
$ brew install ffmpeg
```
ê·¸ëŸ°ë°, ì„¤ì¹˜ê°€ ìê¾¸ ì¤‘ê°„ì— ëŠê¸°ë©´ì„œ í•´ì‹œ ë¶ˆì¼ì¹˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤.
```zsh
Error: mbedtls: SHA256 mismatch
```
ì—¬ëŸ¬ ë°©ë²•ì„ ì‚¬ìš©í–ˆì§€ë§Œ, ê²°êµ­ ë¬¸ì œëŠ” Homebrewê°€ ë‚˜ì˜ ë§¥ OSë¥¼ ì™„ì „í•˜ê²Œ ì§€ì›í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ì—ˆë‹¤.   
ì‚¬ì‹¤ ì„¤ì¹˜í•  ë•Œë¶€í„° ë²„ì „ì´ ë„ˆë¬´ ë‚®ë‹¤ëŠ” ê²½ê³ ì°½ì´ ìˆì—ˆëŠ”ë° ê·¸ë˜ë„ ì„¤ì¹˜ê°€ ìš°ì„ ì´ì—ˆê¸° ë•Œë¬¸ì— ë¬´ì‹œí•˜ê³  ì„¤ì¹˜í–ˆì—ˆë‹¤.   
ê²°êµ­ì—” ì„¤ì¹˜ë„, ëª‡ëª‡ brew ëª…ë ¹ì–´ë„ ì˜ ì‹¤í–‰ë˜ì—ˆê¸° ë•Œë¬¸ì— ë¹„ê³µì‹ ì§€ì›ì´ë¼ë„ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ”êµ¬ë‚˜.. í•˜ê³  ë„˜ê²¼ì—ˆë‹¤.  

ê·¸ëŸ°ë°, ì´ë²ˆì—” ì •ë§ ë¬´ìŠ¨ ë°©ë²•ì„ í•´ë„ ì•ˆëë‹¤.

---

ê²°êµ­ HomebrewëŠ” ì‚­ì œí•˜ê³  ë‚˜ì˜ macOS Monterey (12.7.6) ì„ ì™„ì „íˆ ì§€ì›í•˜ëŠ” íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €, MacPortë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ê²°í–ˆë‹¤.
 
MacPortëŠ” [ê³µì‹ í™ˆí˜ì´ì§€ > Installing MacPorts ë©”ë‰´](https://www.macports.org/install.php)ì—ì„œ ë³¸ì¸ì—ê²Œ ë§ëŠ” OS ë²„ì „ì„ ì„ íƒí•˜ì—¬ .pkg íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì„¤ì¹˜í•˜ë©´ ëœë‹¤.

MacPortì—ì„œ FFMPEGë¥¼ ì„¤ì¹˜í•˜ëŠ” ëª…ë ¹ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤
```zsh
$ sudo port install ffmpeg
```
MacPortë¡œ ì„¤ì¹˜í•˜ëŠ” ë„ì¤‘ì—ëŠ” í•´ì‹œ ê´€ë ¨ ì˜¤ë¥˜ë„ ë‚˜ì§€ ì•Šê³  ì•„ì£¼ ì˜ ì„¤ì¹˜ê°€ ë˜ì—ˆë‹¤.

ë˜í•œ, ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ ê²½ë¡œë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```zsh
# ì…ë ¥í•œ ëª…ë ¹ì–´
$ which ffprobe

# ì¶œë ¥
/opt/local/bin/ffprobe
```
    
**ê²°ë¡ **: ë³¸ì¸ì˜ ê°œë°œ í™˜ê²½ì„ ì§€ì›í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì (ë‹¹ì—°í•œ ì†Œë¦¬ ^..^)
 
&emsp; 
&nbsp;
 
### 1. Voice Chat
ë‹¤ìŒì˜ ìˆœì„œë¡œ ë™ì‘í•˜ëŠ” í”„ë¡œê·¸ë¨ì˜ ì‹¤ìŠµì„ ì§„í–‰í–ˆë‹¤.   
   
    1) í™”ë©´ìƒì—ì„œ ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ë…¹ìŒí•œë‹¤.   
    2) aiê°€ í•´ë‹¹ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•œë‹¤.   
    3) ìœ„ í…ìŠ¤íŠ¸ë¥¼ ì§ˆë¬¸ìœ¼ë¡œ í•˜ì—¬ AIë¥¼ í˜¸ì¶œí•œë‹¤.   
    4) ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í™”ë©´ì— ì±„íŒ… í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•œë‹¤.   
```py
import streamlit as st
from audiorecorder import audiorecorder
from streamlit_chat import message as msg
import openai_api

def main():
    st.set_page_config(
        page_title='Voice Chatbot',
        page_icon="ğŸ‘€",
        layout='wide'
    )
    st.header('Voice Chatbot')
    st.markdown('---')

    with st.expander('Voice Chatbot í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•', expanded=False):
        st.write(
            """ 
            1. ë…¹ìŒí•˜ê¸° ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§ˆë¬¸ì„ ë…¹ìŒí•©ë‹ˆë‹¤.
            2. ë…¹ìŒì´ ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ Whisper ëª¨ë¸ì„ ì´ìš©í•´ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„ LLMì— ì§ˆì˜í•©ë‹ˆë‹¤.
            3. LLMì´ ì‘ë‹µì„ ë‹¤ì‹œ TTS ëª¨ë¸ì„ ì‚¬ìš©í•´ ìŒì„±ìœ¼ë¡œ ë³€í˜¸ë‚˜í•˜ê³  ì´ë¥¼ ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤.
            4. LLMì€ OpenAI ì‚¬ì˜ GPT ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            5. ëª¨ë“  ì§ˆë¬¸/ë‹µë³€ì€ í…ìŠ¤íŠ¸ë¡œë„ ì œê³µí•©ë‹ˆë‹¤.
            """
        )
    
    system_instruction = 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì±—ë´‡ì…ë‹ˆë‹¤.'

    # session state ì´ˆê¸°í™”
    # - chats: ì›¹ í˜ì´ì§€ ì‹œê°í™”ìš© ëŒ€í™”ë‚´ì—­
    # - messages: LLM ì§ˆì˜/ì›¹í˜ì´ì§€ ì‹œê°í™”ë¥¼ ìœ„í•œ ëŒ€í™”ë‚´ì—­
    # - check_reset: ì‚¬ì´ë“œë°” ì´ˆê¸°í™” ë²„íŠ¼ í™œì„±í™”ìš©

    if 'messages' not in st.session_state:
        # ëŒ€í™” ë‚´ì—­ì„ stateë¡œ ë‹´ì•„ì„œ aiê°€ ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µí•˜ê²Œ í•¨
        # ì•±ì´ ì²˜ìŒ ì‹¤í–‰ë  ë•Œ ë”± í•œë²ˆë§Œ ì´ˆê¸°í™”ë˜ë„ë¡ í•¨
        st.session_state['messages'] = [
            {'role': 'system', 'content': system_instruction}
        ]
    
    if 'check_reset' not in st.session_state:
        st.session_state['check_reset'] = False

    with st.sidebar:
            model = st.radio(label='GPT ëª¨ë¸', options=['gpt-3.5-turbo', 'gpt-4-turbo', 'gpt-4o'], index=2)
            print(model)

            if st.button(label='ì´ˆê¸°í™”'):
                st.session_state['messages'] = [
                    {'role': 'system', 'content': system_instruction}
                ]
                st.session_state['check_reset'] = True

    col1, col2 = st.columns(2) # í™”ë©´ì„ ë‘ê°œì˜ ì—´ë¡œ ë‚˜ëˆ„ê³ , ê° í™”ë©´ì„ ë³€ìˆ˜ì— ë‹´ì•„ì¤ë‹ˆë‹¤
    with col1:
        st.subheader('ë…¹ìŒí•˜ê¸°')
        
        audio = audiorecorder()

        if (audio.duration_seconds > 0) and (st.session_state['check_reset'] == False):
            # í™”ë©´ìƒì˜ ì¬ìƒ ê¸°ëŠ¥
            st.audio(audio.export().read())
            query = openai_api.stt(audio)
            print('Q : ', query)
            # ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¡œ session_stateì— ì¶”ê°€í•´ì„œ ëŒ€í™” ê¸°ë¡ì„ ë‚¨ê¸´ë‹¤.
            st.session_state['messages'].append({'role':'user', 'content': query})
            response = openai_api.ask_gpt(st.session_state['messages'], model) # ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•œ ëª¨ë¸ ì „ë‹¬ 
            print('A : ', response)

            # GPT ë‹µë³€ë„ session_stateì— ì¶”ê°€í•´ì¤€ë‹¤.
            st.session_state['messages'].append({"role":"assistant", "content": response})

            #GPT ë‹µë³€ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜
            audio_tag = openai_api.tts(response)
            st.html(audio_tag) # ì‹œê°í™”ë˜ì§€ ì•Šê³ , ìë™ìœ¼ë¡œ ì¬ìƒ (ì¦‰ì‹œ ì¬ìƒ ê°€ëŠ¥í•œ html íƒœê·¸)

    with col2:
        st.subheader('ì§ˆë¬¸/ë‹µë³€')
        if(audio.duration_seconds > 0) and (st.session_state['check_reset'] == False ):
            for i, message in enumerate(st.session_state['messages']): # indexê°’ê¹Œì§€ í™œìš© ëª©ì 
                role = message['role']
                content = message['content']
                if role == 'user':
                    msg(content, is_user=True, key=str(i), avatar_style="big-smile")
                elif role == 'assistant':
                    msg(content, is_user=False, key=str(i), avatar_style="fun-emoji")
        else:
            st.session_state['check_reset'] = False # ë§Œì•½ ëŒ€í™”ê°€ ì—†ë‹¤ë©´ ì´ˆê¸°í™”


if __name__ == '__main__':
    main()
```

```py
from dotenv import load_dotenv
from openai import OpenAI
import base64
import os

load_dotenv()

client = OpenAI()

def stt(audio):
    filename = 'temp.mp3' # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥í•  ì„ì‹œ íŒŒì¼ ì´ë¦„
    audio.export(filename, format='mp3')

    with open(filename, 'rb') as f:
        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=f
        )
    os.remove(filename) # ì„ì‹œíŒŒì¼ ì‚­ì œ
    return transcription.text

def ask_gpt(messages, model):
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=1,
        max_tokens=4096,
        top_p=1
    )
    return response.choices[0].message.content

def tts(text):
    filename = "output.mp3"
    with client.audio.speech.with_streaming_response.create(
        model='tts-1',
        voice='echo',
        input=text
    ) as response:
        response.stream_to_file(filename)

    #Base64 ì¸ì½”ë”© : ìŒì„± íŒŒì¼ ë°ì´í„° ìì²´ë¥¼ ì•„ì£¼ ê¸´ í…ìŠ¤íŠ¸ (base64)ë¡œ ë³€í™˜í•œë‹¤.
    with open(filename, 'rb') as f:
        data = f.read()
        b64_encoded = base64.b64encode(data).decode()
        audio_tag = f""" 
        <audio autoplay="true">
            <source src="data:audio/mp3;base64,{b64_encoded}" type='audio/mp3'/>
        </audio>
        """
    os.remove(filename) # ì›ë³¸ ì‚­ì œ

    return audio_tag # íŒŒì¼ì´ ì•„ë‹Œ, ì˜¤ë””ì˜¤ ì ë³´ê°€ ë‹´ê¸´ HTML ì½”ë“œ ì¡°ê°ì„ ë°˜í™˜
```
